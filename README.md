# local-chat
IOS app which runs LLM inference locally
